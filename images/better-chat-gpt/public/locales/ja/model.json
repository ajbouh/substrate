{
  "configuration": "設定",
  "model": "モデル",
  "token": {
    "label": "最大トークン数",
    "description": "チャット完了時に生成するトークンの最大数。入力トークンと生成されたトークンの合計長は、モデルのコンテキスト長で制限されます。"
  },
  "default": "デフォルト",
  "temperature": {
    "label": "温度",
    "description": "使用するサンプリング温度。0から2までの間で指定します。0.8などの高い値は、出力をよりランダムにします。一方、0.2などの低い値は、より焦点を絞って決定論的にします。通常、これまたはtop pを変更することをお勧めしますが、両方を変更しないでください。(デフォルト：1)"
  },
  "presencePenalty": {
    "label": "存在ペナルティ",
    "description": "-2.0から2.0までの数値。正の値は、新しいトークンがテキストに現れるかどうかに基づいて新しいトピックについて話すモデルの可能性を高めるため、新しいトークンにペナルティを課します。(デフォルト：0)"
  },
  "topP": {
    "label": "トップp",
    "description": "0から1の数値。温度を使ったサンプリングの代わりに、モデルはトップp確率質量を持つトークンの結果を考慮する核サンプリングと呼ばれる手法を使用します。つまり、0.1は確率質量の上位10％を占めるトークンのみが考慮されます。通常、これまたは温度のどちらか一方を変更することをお勧めします。（デフォルト：1）"
  },
  "frequencyPenalty": {
    "label": "頻度ペナルティ",
    "description": "-2.0から2.0の数値。正の値は、テキスト内での新しいトークンの既存の頻度に基づいて新しいトークンにペナルティを課し、同じ行をそのまま繰り返す可能性を減らします。（デフォルト：0）"
  },
  "defaultChatConfig": "デフォルトチャット設定",
  "defaultSystemMessage": "デフォルトシステムメッセージ",
  "resetToDefault": "デフォルトにリセット"
}
